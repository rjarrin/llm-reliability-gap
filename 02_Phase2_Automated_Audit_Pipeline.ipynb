{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2: Solution Synthesis and Artifact Generation\n",
        "\n",
        "### **Overview**\n",
        "This notebook contains the execution pipeline for **Phase 2 (Steps 2-6)** of the methodology. It ingests the standardized C programming problems generated in Phase 1 and systematically prompts the target Large Language Models (LLMs) to generate the corresponding solutions and pedagogical artifacts.\n",
        "\n",
        "### **Methodology**\n",
        "For each problem in the generated dataset, the pipeline maintains a continuous conversational context and tasks the evaluated models with producing:\n",
        "* **Step 2 (Solution):** A fully implemented, standard-compliant (C11) code solution.\n",
        "* **Step 3 (Explanation):** A conceptual, step-by-step breakdown of the underlying logic.\n",
        "* **Step 4 (Hints):** Progressively helpful, syntax-free conceptual nudges for students.\n",
        "* **Step 5 (Summary):** A bulleted list of core learning objectives mapped to the solution.\n",
        "* **Step 6 (Test Cases):** A machine-readable JSON array of inputs/outputs for dynamic testing.\n",
        "\n",
        "**Evaluated Models:** This synthesis is performed across the four target architectures analyzed in the study: Llama-3.3-70b, Moonshot Kimi K2, OpenAI (GPT-OSS 120B), and Qwen 3 32B.\n",
        "\n",
        "**Target Output:** A comprehensive, consolidated JSONL dataset containing the complete 1195-iteration corpus, which serves as the direct input for the Phase 3 Automated Audit Pipeline.\n",
        "\n",
        "---\n",
        "**Note for Double-Blind Review:** This codebase has been fully anonymized. Please ensure you provide your own API keys in the environment variables before execution, and update the file paths to point to your Phase 1 output files."
      ],
      "metadata": {
        "id": "Z8GS-o381901"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Environment Setup & Dependency Installation\n",
        "This cell initializes the Python environment required for the Phase 2 Solution Synthesis pipeline. It installs the `groq` client library, imports necessary data-handling modules, and mounts the local Google Drive.\n",
        "\n",
        "Mounting the drive establishes the file path connection needed to read the problem bank generated in Phase 1, and allows for persistent, batch-by-batch saving of the generated solutions.\n",
        "\n",
        "> **Note:** For double-blind execution, you must provide your own Groq API key by replacing the placeholder string below."
      ],
      "metadata": {
        "id": "jJTYblh22kHl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaF-eaT914Co"
      },
      "outputs": [],
      "source": [
        "# 1. Install the official Groq library\n",
        "!pip install -q groq\n",
        "\n",
        "import os, json, time, re\n",
        "from google.colab import drive\n",
        "from groq import Groq\n",
        "from datetime import datetime\n",
        "\n",
        "# 2. Set API Key (ANONYMIZED FOR DOUBLE-BLIND REVIEW)\n",
        "# Reviewers: Please insert your own Groq API key below.\n",
        "os.environ[\"GROQ_API_KEY\"] = \"YOUR_GROQ_API_KEY_HERE\"\n",
        "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "# 3. Mount Google Drive (for persistent storage of the generated problem bank)\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Data Ingestion & Standardization (The 300-Problem Bank)\n",
        "Before solution synthesis begins, the raw outputs from Phase 1 must be aggregated, deduplicated, and standardized.\n",
        "\n",
        "This cell scans the Phase 1 output directories, extracts the generated `step_1` problem statements, and preserves the provenance metadata (which model generated it and during which iteration). It then enforces the dataset constraints by batching exactly 100 unique problems per topic.\n",
        "\n",
        "To facilitate human verification alongside automated processing, this script outputs both machine-readable JSON batches and formatted Markdown previews."
      ],
      "metadata": {
        "id": "MnnOvOR128SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2\n",
        "# --- PROBLEM EXTRACTION & BATCHING SYSTEM WITH METADATA ---\n",
        "import os, json, glob\n",
        "\n",
        "# Ensure these folders exist in your Drive\n",
        "input_folder = \"/content/drive/MyDrive/CANAI_LLM_Results\"\n",
        "output_folder = \"/content/drive/MyDrive/CANAI_LLM_Results/Standardized_Problems/\"\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    print(f\"Created directory: {output_folder}\")\n",
        "\n",
        "eval_folder = \"/content/drive/MyDrive/CANAI_LLM_Results/Eval/\"\n",
        "\n",
        "if not os.path.exists(eval_folder):\n",
        "    os.makedirs(eval_folder, exist_ok=True)\n",
        "    print(f\"Created directory: {eval_folder}\")\n",
        "\n",
        "# Map filenames to your three specific topics\n",
        "topic_map = {\n",
        "    \"Pointers_and_Pointer_Arithmetic\": [],\n",
        "    \"Dynamic_Memory_Allocation_(malloc,_free)\": [],\n",
        "    \"Implementing_Data_Structures_(e.g.,_Singly_Linked_Lists)\": []\n",
        "}\n",
        "\n",
        "# 1. Extract Step 1 and Metadata from all JSONL files\n",
        "jsonl_files = glob.glob(os.path.join(input_folder, \"*.jsonl\"))\n",
        "print(f\"Found {len(jsonl_files)} JSONL files to process.\")\n",
        "\n",
        "for file_path in jsonl_files:\n",
        "    # Identify topic from filename\n",
        "    current_topic = None\n",
        "    for topic_key in topic_map.keys():\n",
        "        if topic_key in file_path:\n",
        "            current_topic = topic_key\n",
        "            break\n",
        "\n",
        "    if not current_topic: continue\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                if \"step_1\" in data.get(\"steps\", {}):\n",
        "                    problem_text = data[\"steps\"][\"step_1\"]\n",
        "                    # Extract source metadata\n",
        "                    source_model = data.get(\"model\", \"Unknown Model\")\n",
        "                    source_iter = data.get(\"iteration\", \"N/A\")\n",
        "\n",
        "                    # Create a metadata package\n",
        "                    problem_entry = {\n",
        "                        \"text\": problem_text,\n",
        "                        \"model\": source_model,\n",
        "                        \"iteration\": source_iter\n",
        "                    }\n",
        "\n",
        "                    # Check for duplicates using the text only\n",
        "                    existing_texts = [p[\"text\"] for p in topic_map[current_topic]]\n",
        "                    if problem_text not in existing_texts:\n",
        "                        topic_map[current_topic].append(problem_entry)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "# 2. Save into batches of 100 (BOTH JSON AND MD)\n",
        "for topic, problems in topic_map.items():\n",
        "    print(f\"\\nProcessing Topic: {topic} | Unique Problems: {len(problems)}\")\n",
        "\n",
        "    for i in range(0, len(problems), 100):\n",
        "        batch = problems[i : i + 100]\n",
        "        if not batch: continue\n",
        "\n",
        "        batch_num = (i // 100) + 1\n",
        "\n",
        "        # Define Filenames\n",
        "        json_batch_filename = f\"{output_folder}{topic}_Batch_{batch_num}.json\"\n",
        "        md_preview_filename = f\"{output_folder}{topic}_Batch_{batch_num}_PREVIEW.md\"\n",
        "\n",
        "        # --- SAVE JSON BATCH (Contains objects instead of just strings) ---\n",
        "        with open(json_batch_filename, \"w\") as jf:\n",
        "            json.dump(batch, jf)\n",
        "\n",
        "        # --- SAVE MD PREVIEW (With formatted headers) ---\n",
        "        with open(md_preview_filename, \"w\") as md_file:\n",
        "            md_file.write(f\"# Problem Batch Preview: {topic.replace('_', ' ')}\\n\")\n",
        "            md_file.write(f\"**Batch Number:** {batch_num} | **Total Problems:** {len(batch)}\\n\\n\")\n",
        "            md_file.write(\"---\\n\\n\")\n",
        "\n",
        "            for idx, prob in enumerate(batch):\n",
        "                # Format: ## Problem X - Model Name - Iteration Y\n",
        "                header = f\"## Problem {idx + 1} - {prob['model']} - Iteration {prob['iteration']}\"\n",
        "                md_file.write(f\"{header}\\n\")\n",
        "                md_file.write(f\"{prob['text']}\\n\\n\")\n",
        "                md_file.write(\"---\\n\\n\")\n",
        "\n",
        "        print(f\"Saved Batch {batch_num}:\")\n",
        "        print(f\"    - JSON: {os.path.basename(json_batch_filename)}\")\n",
        "        print(f\"    - MD:   {os.path.basename(md_preview_filename)}\")"
      ],
      "metadata": {
        "id": "Jaj1BPg8285E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Solution Synthesis & Artifact Generation (Solver Mode)\n",
        "This cell executes **Steps 2 through 6** of the methodology. It reads the standardized problem batches from Phase 1 and tasks the evaluated models with synthesizing the C11-compliant solutions, Socratic hints, conceptual explanations, and machine-readable JSON test suites.\n",
        "\n",
        "**Double-Blind Reviewer Note:** A `TEST_MODE` toggle is provided below. When set to `True`, the script will only process the first 5 problems of the selected batch. This allows for quick verification of the prompt chain and dynamic test generation without incurring significant API token costs or requiring long execution times."
      ],
      "metadata": {
        "id": "X_Op_2sW3DEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RESEARCH CONFIGURATION (SOLVER MODE) ---\n",
        "#MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
        "#MODEL_NAME = \"openai/gpt-oss-120b\"\n",
        "MODEL_NAME = \"qwen/qwen3-32b\"\n",
        "#MODEL_NAME = \"moonshotai/kimi-k2-instruct-0905\"\n",
        "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "# 1. SELECT THE BATCH TO SOLVE\n",
        "topics = [\n",
        "    \"Pointers_and_Pointer_Arithmetic\",\n",
        "    \"Dynamic_Memory_Allocation_(malloc,_free)\",\n",
        "    \"Implementing_Data_Structures_(e.g.,_Singly_Linked_Lists)\"\n",
        "]\n",
        "SELECTED_TOPIC = topics[0] # 0, 1, or 2\n",
        "BATCH_NUM = 1 # 1, 2, or 3\n",
        "\n",
        "# Load the standardized problems\n",
        "input_batch_file = f\"/content/drive/MyDrive/CANAI_LLM_Results/Standardized_Problems/{SELECTED_TOPIC}_Batch_{BATCH_NUM}.json\"\n",
        "with open(input_batch_file, \"r\") as f:\n",
        "    ALL_PROBLEMS = json.load(f)\n",
        "\n",
        "\n",
        "# --- TEST OVERRIDE: Change this to True to run only 5 problems ---\n",
        "TEST_MODE = False\n",
        "\n",
        "if TEST_MODE:\n",
        "   PROBLEM_LIST = ALL_PROBLEMS[:5] # Takes only the first 5\n",
        "   print(f\"TEST MODE ACTIVE: Processing only {len(PROBLEM_LIST)} problems.\")\n",
        "else:\n",
        "   PROBLEM_LIST = ALL_PROBLEMS\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# Output filename\n",
        "filename = f\"/content/drive/MyDrive/CANAI_LLM_Results/Eval/SOLVED_{current_date}_{MODEL_NAME.replace('/', '_')}_{SELECTED_TOPIC}_B{BATCH_NUM}.jsonl\"\n",
        "\n",
        "# We removed Step 1 from prompts since we already have it\n",
        "prompts = [\n",
        "    \"\"\"# STEP 2: SOLUTION\n",
        "    Based on the problem provided in the previous message, provide a complete and correct C solution. Your response must begin with the header # STEP 2: SOLUTION.\n",
        "    The code must be well-commented to explain the logic of key sections. It must follow modern C standards (e.g., C11), include all necessary headers, and be formatted for readability.\n",
        "    CRITICAL:\n",
        "    - The code MUST check the return value of all malloc/realloc calls.\n",
        "    - All allocated memory MUST be freed before exit.\n",
        "    - Follow the constraints outlined in the problem.\"\"\",\n",
        "\n",
        "    f\"\"\"# STEP 3: EXPLANATION\n",
        "    Regarding the solution code you just provided, write a clear, step-by-step explanation of how it works. Your response must begin with the header # STEP 3: EXPLANATION.\n",
        "    Your explanation should be aimed at a student who understands the basic syntax of C but is struggling with {SELECTED_TOPIC}.\n",
        "    Do not just describe what the code does line-by-line; explain the underlying concepts and the 'why' behind the implementation decisions.\"\"\",\n",
        "\n",
        "    f\"\"\"# STEP 4: HINTS\n",
        "    Now, imagine a student is stuck on the original problem you created and has not yet seen the solution.\n",
        "    Generate a series of three progressively more helpful hints to guide them. The hints must not give away the code.\n",
        "    Your response must begin with the header # STEP 4: HINTS.\n",
        "    CRITICAL GUARDRAIL: The hints must not give away any actual C code syntax.\n",
        "    Hint 1: Should be a high-level conceptual nudge about the overall approach.\n",
        "    Hint 2: Should point them toward a specific part of the problem or a key C feature to use.\n",
        "    Hint 3: Should be more direct, suggesting a specific logic structure or the first step to take.\"\"\",\n",
        "\n",
        "    f\"\"\"# STEP 5: SUMMARY\n",
        "    Step 5: Finally, provide a concise summary of the key learning objectives that this problem-solution pair covers.\n",
        "    The summary should be in bullet-point format and highlight the main C programming concepts a student would master by completing this exercise.\n",
        "    Your response must begin with the header # STEP 5: SUMMARY.\"\"\",\n",
        "\n",
        "    f\"\"\"# STEP 6: TEST CASES\n",
        "    For the problem you generated, create a comprehensive suite of 5 test cases. Include at least one common case, one edge case (e.g., empty input, null pointer, zero value), and one invalid input case to test the program's error handling. Your response must begin with the header # STEP 6: TEST CASES.\n",
        "\n",
        "    CRITICAL FOR AUTOMATION:\n",
        "    After your descriptions, you MUST provide a machine-readable JSON block.\n",
        "    containing the raw strings that a user would type to execute these tests. Ensure newlines within the JSON string are represented as literal '\\n' characters and not actual line breaks.\n",
        "\n",
        "    FOLLOW THIS EXACT STRUCTURE AND FORMAT FOR YOUR JSON BLOCK (i.e., exit_command, test_suite, input, expected_keyword):\n",
        "    ```json\n",
        "    {{\n",
        "      \"exit_command\": \"4\",\n",
        "      \"test_suite\": [\n",
        "        {{\"input\": \"1\\\\nJohn\\\\n100\", \"expected_keyword\": \"John\"}},\n",
        "        {{\"input\": \"2\\\\nJohn\", \"expected_keyword\": \"removed\"}}\n",
        "      ]\n",
        "    }}\n",
        "    ```\"\"\"\n",
        "]\n",
        "\n",
        "print(f\"Solving Topic: {SELECTED_TOPIC} | Batch: {BATCH_NUM}\")\n",
        "print(f\"Saving to: {filename}\")\n",
        "\n",
        "# Process each problem in the batch\n",
        "for idx, problem_entry in enumerate(PROBLEM_LIST):\n",
        "    # Retrieve the text from the dictionary\n",
        "    problem_text = problem_entry[\"text\"]\n",
        "    original_model = problem_entry[\"model\"]\n",
        "    original_iter = problem_entry[\"iteration\"]\n",
        "\n",
        "    print(f\"\\nSOLVING PROBLEM {idx+1} (Source: {original_model} Iter: {original_iter})...\")\n",
        "\n",
        "    module_data = {\n",
        "        \"iteration\": idx + 1,\n",
        "        \"topic\": SELECTED_TOPIC,\n",
        "        \"model\": MODEL_NAME, # Current solver model\n",
        "        \"source_metadata\": f\"{original_model}_iter_{original_iter}\", # Preserve origin\n",
        "        \"steps\": {\"step_1\": problem_text}\n",
        "    }\n",
        "\n",
        "    # Initialize history with the specific problem to be solved\n",
        "    history = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a CS Professor and Socratic Tutor.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Here is a programming problem. I need you to provide the solution and educational content for it.\\n\\n{problem_text}\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"I have received the problem. Please provide the next instructions.\"}\n",
        "    ]\n",
        "\n",
        "    step_idx = 0\n",
        "    while step_idx < len(prompts):\n",
        "        try:\n",
        "            history.append({\"role\": \"user\", \"content\": prompts[step_idx]})\n",
        "            completion = client.chat.completions.create(\n",
        "                model=MODEL_NAME,\n",
        "                messages=history,\n",
        "                temperature=0.0,\n",
        "                reasoning_effort=\"none\" #For Qwen3 only. Comment this part for other models\n",
        "            )\n",
        "            answer = completion.choices[0].message.content\n",
        "\n",
        "            print(f\"--- Step {step_idx + 2} Completed ---\")\n",
        "\n",
        "            # Key matches your original format (step_2, step_3, etc.)\n",
        "            module_data[\"steps\"][f\"step_{step_idx + 2}\"] = answer\n",
        "            history.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "            step_idx += 1\n",
        "            time.sleep(12)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"!!!! API Error: {e}\")\n",
        "            raise\n",
        "\n",
        "    # Save to JSONL after each problem is fully solved\n",
        "    with open(filename, \"a\") as f:\n",
        "        f.write(json.dumps(module_data) + \"\\n\")\n",
        "\n",
        "print(f\"Batch completed.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "TvBhOGmJ3JG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Artifact Generation: Solved Markdown Report\n",
        "This final cell converts the fully synthesized, machine-readable JSONL dataset into a human-readable Markdown (`.md`) format.\n",
        "\n",
        "This supplementary artifact allows peer reviewers and educators to easily perform qualitative assessments of the generated solutions, pedagogical explanations, and Socratic hints, while explicitly tracking the provenance (source model and iteration) of the original problem constraint."
      ],
      "metadata": {
        "id": "XnVyjc143KmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-initialize safe names in case this cell is run independently\n",
        "safe_model_name = MODEL_NAME.replace('/', '_')\n",
        "safe_topic_name = SELECTED_TOPIC.replace(' ', '_')\n",
        "\n",
        "filename = f\"/content/drive/MyDrive/CANAI_LLM_Results/Eval/SOLVED_{current_date}_{safe_model_name}_{safe_topic_name}_B{BATCH_NUM}.jsonl\"\n",
        "report_file = f\"/content/drive/MyDrive/CANAI_LLM_Results/Eval/Readable_Report_SOLVED_{current_date}_{safe_model_name}_{safe_topic_name}_B{BATCH_NUM}.md\"\n",
        "\n",
        "with open(filename, \"r\") as f, open(report_file, \"w\") as out:\n",
        "    out.write(f\"# C Education Standardized Research Report: {SELECTED_TOPIC.replace('_', ' ')}\\n\")\n",
        "    out.write(f\"**Solver Model:** {MODEL_NAME} | **Date:** {current_date} | **Batch:** {BATCH_NUM}\\n\\n\")\n",
        "    out.write(\"---\\n\\n\")\n",
        "\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        if not data[\"steps\"]: continue\n",
        "\n",
        "        # Display Iteration and the Original Source Metadata\n",
        "        source_info = data.get(\"problem_source\", \"Unknown Source\")\n",
        "        out.write(f\"## Iteration {data['iteration']} (Problem Source: {source_info})\\n\")\n",
        "\n",
        "        for step_num in range(1, 7):\n",
        "            key = f\"step_{step_num}\"\n",
        "            out.write(f\"### {key.upper()}\\n\")\n",
        "            out.write(f\"{data['steps'].get(key, 'Empty Step')}\\n\\n\")\n",
        "        out.write(\"---\\n\\n\")\n",
        "\n",
        "print(f\"Readable report created: {os.path.basename(report_file)}\")"
      ],
      "metadata": {
        "id": "2s7hOA553MMQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}